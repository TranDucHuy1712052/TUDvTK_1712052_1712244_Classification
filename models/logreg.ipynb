{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class DataPack:\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "## Điều kiện sử dụng: Cả 2 tập dữ liệu train/test đều phải cùng 1 kiểu (cùng 1 bộ hoặc là cùng cấu trúc, quy tắc...)\n",
    "class DataReader:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.encoders = []                      ## các encoder cho tập dữ liệu này\n",
    "        self.atrNames = []                     ## tên các thuộc tính\n",
    "        self.atrVals = []                        ## tập giá trị của từng thuộc tính (-1 nếu là biến liên tục)\n",
    "\n",
    "    ## đọc file ban đầu, nạp vào các biến\n",
    "    def ReadDataDescription(self, url):\n",
    "        f = open(url)\n",
    "        lines = f.readlines()\n",
    "        names = []\n",
    "        vals = []\n",
    "        for line in lines:\n",
    "            _line = line.split(':')\n",
    "            _line[0] = _line[0].strip(' \\t\\n\\r')        # xóa hết dấu cách và enter\n",
    "            names.append(_line[0])\n",
    "            val = _line[1].split(',')\n",
    "            for i in range(0, len(val)):\n",
    "                val[i] = [val[i].strip(' \\t\\n\\r')]\n",
    "            vals.append(val)\n",
    "        print(\"Data attributes found: \", names)\n",
    "        self.__Initialize(names, vals)\n",
    "\n",
    "    def __Initialize(self, atrNames, atrVals):\n",
    "        self.atrNames = atrNames\n",
    "        self.atrVals = atrVals\n",
    "        ## self.__EncodeData()\n",
    "\n",
    "    def __IsContinuous(self, idx):\n",
    "        return (self.atrVals[idx] == [['continuous']])\n",
    "\n",
    "    ## trả về dataPack \n",
    "    def readData(self, url):\n",
    "        df = pd.read_csv(url, header=0)\n",
    "        df.dropna()\n",
    "        print(\"Data shape = \", df.shape)\n",
    "        self.__TrimStrings(df)\n",
    "        self.__FindNull(df)\n",
    "        print(df.columns)\n",
    "\n",
    "        encodedColumns = pd.DataFrame()\n",
    "        ## encode các cột theo dạng category => one hot encoding\n",
    "        for i in range(0, len(self.atrNames) ):\n",
    "            #if (self.encoders[i] != None):          # không phải None => có encode rồi\n",
    "            if not (self.__IsContinuous(i)):\n",
    "                #enc = self.encoders[i]              # lấy encoder tương ứng với cột này\n",
    "                col = df.columns[i]\n",
    "                \n",
    "                # duyệt từng phần tử trong cột và encode\n",
    "                # newDF = pd.DataFrame()\n",
    "                # for entry in df[col]:\n",
    "                #     tmpDF = pd.DataFrame( enc.transform([ [entry] ]).toarray() )\n",
    "                #     pd.concat([newDF, tmpDF], axis=0)\n",
    "                newDF = pd.get_dummies(df[col], prefix=df.columns[i])\n",
    "                ## print(newDF, '\\n\\n')\n",
    "\n",
    "                encodedColumns = pd.concat([encodedColumns, newDF], axis=1)\n",
    "                print(\"Column\", df.columns[i], \"encoded.\")\n",
    "        \n",
    "        dropIdx = []\n",
    "        for i in range(0, len(self.atrNames) ):\n",
    "            if not (self.__IsContinuous(i)):\n",
    "                col = df.columns[i]\n",
    "                print(\"Deleting column : \", col)\n",
    "                dropIdx.append(col)\n",
    "        df.drop(columns=dropIdx, inplace=True)\n",
    "        \n",
    "        ##print(encodedColumns)\n",
    "        result = pd.concat( [df, encodedColumns], axis=1 )   \n",
    "\n",
    "        labels = result[\"label\"]\n",
    "        result.drop(columns=\"label\", inplace=True)            #gỡ ra khỏi dataframe để khỏi bị trùng lắp\n",
    "       ## labels_encoded = pd.get_dummies(labels)\n",
    "\n",
    "        features = result\n",
    "        dataPack = DataPack(features, labels)\n",
    "        print(\"Read file succesfully.\")\n",
    "        print( pd.concat([result, labels], axis=1) )\n",
    "        return dataPack\n",
    "\n",
    "    def readTrainData(self, url):\n",
    "        print(\"[!] Train data reading...\\n\\n\")\n",
    "        pack = self.readData(url)\n",
    "        self.train = pack\n",
    "        print(\"[!] Train data read successfully!\\n\\n\")\n",
    "\n",
    "    def readTestData(self, url):\n",
    "        print(\"[!] Test data reading...\\n\\n\")\n",
    "        pack = self.readData(url)\n",
    "        self.test = pack\n",
    "        print(\"[!] Test data read successfully!\\n\\n\")\n",
    "\n",
    "    ## dữ liệu có dấu '?' tức là bị thiếu/mất\n",
    "    def __FindNull(self, df):\n",
    "        rows = df.shape[0]\n",
    "        cols = df.shape[1]\n",
    "        print(\"Finding missing values... \")\n",
    "        for i in range(0, rows):\n",
    "            for j in range(0, cols):\n",
    "                if (df.iat[i,j] == '?'):\n",
    "                    df.iat[i,j] = np.nan\n",
    "\n",
    "\n",
    "    def __TrimStrings(self, df: pd.DataFrame()):\n",
    "        rows = df.shape[0]\n",
    "        cols = df.shape[1]\n",
    "        print(\"Trimming strings...\")\n",
    "        for i in range(0, rows):\n",
    "            for j in range(0, cols):\n",
    "                if (type( df.iat[i,j] ) == str):\n",
    "                    df.iat[i,j] = df.iat[i,j].strip(' \\t\\n\\r')\n",
    "\n",
    "    ## encode nó sang dạng one-hot để có thể chạy được trên các mô hình\n",
    "    def __EncodeData(self):\n",
    "        print(\"Encoding categories...\")\n",
    "        for i in range(0, len(self.atrNames) ):\n",
    "            if (self.atrVals[i] == [['continuous']]):\n",
    "                self.encoders.append(None)\n",
    "            else:\n",
    "                vals = self.atrVals[i]            ## 2D array\n",
    "                encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "                encoder.fit(vals)\n",
    "                self.encoders.append(encoder)\n",
    "                print(\"Attribute \", self.atrNames[i], \" encoded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Train data reading...\n",
      "\n",
      "\n",
      "Data shape =  (32561, 15)\n",
      "Trimming strings...\n",
      "Finding missing values... \n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'label'],\n",
      "      dtype='object')\n",
      "Read file succesfully.\n",
      "       age         workclass  fnlwgt   education  education-num  \\\n",
      "0       39         State-gov   77516   Bachelors             13   \n",
      "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
      "2       38           Private  215646     HS-grad              9   \n",
      "3       53           Private  234721        11th              7   \n",
      "4       28           Private  338409   Bachelors             13   \n",
      "...    ...               ...     ...         ...            ...   \n",
      "32556   27           Private  257302  Assoc-acdm             12   \n",
      "32557   40           Private  154374     HS-grad              9   \n",
      "32558   58           Private  151910     HS-grad              9   \n",
      "32559   22           Private  201490     HS-grad              9   \n",
      "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
      "\n",
      "           marital-status         occupation   relationship   race     sex  \\\n",
      "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "...                   ...                ...            ...    ...     ...   \n",
      "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
      "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
      "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
      "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
      "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week native-country  label  \n",
      "0              2174             0              40  United-States  <=50K  \n",
      "1                 0             0              13  United-States  <=50K  \n",
      "2                 0             0              40  United-States  <=50K  \n",
      "3                 0             0              40  United-States  <=50K  \n",
      "4                 0             0              40           Cuba  <=50K  \n",
      "...             ...           ...             ...            ...    ...  \n",
      "32556             0             0              38  United-States  <=50K  \n",
      "32557             0             0              40  United-States   >50K  \n",
      "32558             0             0              40  United-States  <=50K  \n",
      "32559             0             0              20  United-States  <=50K  \n",
      "32560         15024             0              40  United-States   >50K  \n",
      "\n",
      "[32561 rows x 15 columns]\n",
      "[!] Train data read successfully!\n",
      "\n",
      "\n",
      "[!] Test data reading...\n",
      "\n",
      "\n",
      "Data shape =  (16281, 15)\n",
      "Trimming strings...\n",
      "Finding missing values... \n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'label'],\n",
      "      dtype='object')\n",
      "Read file succesfully.\n",
      "       age     workclass  fnlwgt     education  education-num  \\\n",
      "0       25       Private  226802          11th              7   \n",
      "1       38       Private   89814       HS-grad              9   \n",
      "2       28     Local-gov  336951    Assoc-acdm             12   \n",
      "3       44       Private  160323  Some-college             10   \n",
      "4       18           NaN  103497  Some-college             10   \n",
      "...    ...           ...     ...           ...            ...   \n",
      "16276   39       Private  215419     Bachelors             13   \n",
      "16277   64           NaN  321403       HS-grad              9   \n",
      "16278   38       Private  374983     Bachelors             13   \n",
      "16279   44       Private   83891     Bachelors             13   \n",
      "16280   35  Self-emp-inc  182148     Bachelors             13   \n",
      "\n",
      "           marital-status         occupation    relationship  \\\n",
      "0           Never-married  Machine-op-inspct       Own-child   \n",
      "1      Married-civ-spouse    Farming-fishing         Husband   \n",
      "2      Married-civ-spouse    Protective-serv         Husband   \n",
      "3      Married-civ-spouse  Machine-op-inspct         Husband   \n",
      "4           Never-married                NaN       Own-child   \n",
      "...                   ...                ...             ...   \n",
      "16276            Divorced     Prof-specialty   Not-in-family   \n",
      "16277             Widowed                NaN  Other-relative   \n",
      "16278  Married-civ-spouse     Prof-specialty         Husband   \n",
      "16279            Divorced       Adm-clerical       Own-child   \n",
      "16280  Married-civ-spouse    Exec-managerial         Husband   \n",
      "\n",
      "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
      "0                   Black    Male             0             0              40   \n",
      "1                   White    Male             0             0              50   \n",
      "2                   White    Male             0             0              40   \n",
      "3                   Black    Male          7688             0              40   \n",
      "4                   White  Female             0             0              30   \n",
      "...                   ...     ...           ...           ...             ...   \n",
      "16276               White  Female             0             0              36   \n",
      "16277               Black    Male             0             0              40   \n",
      "16278               White    Male             0             0              50   \n",
      "16279  Asian-Pac-Islander    Male          5455             0              40   \n",
      "16280               White    Male             0             0              60   \n",
      "\n",
      "      native-country   label  \n",
      "0      United-States  <=50K.  \n",
      "1      United-States  <=50K.  \n",
      "2      United-States   >50K.  \n",
      "3      United-States   >50K.  \n",
      "4      United-States  <=50K.  \n",
      "...              ...     ...  \n",
      "16276  United-States  <=50K.  \n",
      "16277  United-States  <=50K.  \n",
      "16278  United-States  <=50K.  \n",
      "16279  United-States  <=50K.  \n",
      "16280  United-States   >50K.  \n",
      "\n",
      "[16281 rows x 15 columns]\n",
      "[!] Test data read successfully!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataReader = DataReader()\n",
    "# dataReader.ReadDataDescription('data/adult.names.txt')\n",
    "dataReader.readTrainData(r'C:\\Users\\Thinh\\Desktop\\TUDvTK_1712052_1712244_Classification-master\\data\\adult.train.csv')\n",
    "dataReader.readTestData(r'C:\\Users\\Thinh\\Desktop\\TUDvTK_1712052_1712244_Classification-master\\data\\adult.test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataReader.train.features\n",
    "testX = dataReader.test.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thinh\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "C:\\Users\\Thinh\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1418: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "# X = pd.get_dummies(data = X, columns = ['workclass', 'fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])\n",
    "X = pd.get_dummies(data = X, columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])\n",
    "testX = pd.get_dummies(data = testX, columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])\n",
    "col_list = (X.append([testX])).columns.tolist()\n",
    "\n",
    "X = X.loc[:, col_list].fillna(0)\n",
    "testX = testX.loc[:, col_list].fillna(0)\n",
    "\n",
    "fnlwgt = {}\n",
    "marital_status = {}\n",
    "occupation = {}\n",
    "relationship = {}\n",
    "workclass = {}\n",
    "race = {}\n",
    "sex = {}\n",
    "native_country = {}\n",
    "columns = ['occupation', 'workclass', 'sex']\n",
    "dict_list = [occupation, workclass, sex]\n",
    "\n",
    "# delete_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "# delete_features = ['education']\n",
    "def preprocessingData(X):\n",
    "#     for i in delete_features:\n",
    "#         X.drop(columns = i, axis=1, inplace = True)\n",
    "#     for index, row in X.iterrows():\n",
    "#         for i in range(len(columns)):\n",
    "#             if row[columns[i]] not in dict_list[i]:\n",
    "#                 dict_list[i][row[columns[i]]] = len(dict_list[i])\n",
    "#             X.loc[index, columns[i]] = dict_list[i][row[columns[i]]]\n",
    "\n",
    "#         if row['marital-status'] not in marital_status:\n",
    "#             marital_status[row['marital-status']] = len(marital_status)\n",
    "#         X.loc[index, 'marital-status'] = marital_status[row['marital-status']]\n",
    "\n",
    "#         if row['native-country'] not in native_country:\n",
    "#             native_country[row['native-country']] = len(native_country)\n",
    "#         X.loc[index, 'native-country'] = native_country[row['native-country']]\n",
    "\n",
    "    needScale = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    for i in needScale:\n",
    "        X[i] = X[i]/(X[i].max())\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessingData(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataReader.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thinh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Thinh\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y)):\n",
    "    if(y[i] == \"<=50K\"):\n",
    "        y[i] = 0\n",
    "    else:\n",
    "        y[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.T\n",
    "y = y.T\n",
    "X = np.concatenate((np.ones((1, X.shape[1])), X), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return 1/(1 + np.exp(-s))\n",
    "\n",
    "def logistic_sigmoid_regression(X, y, w_init, eta, tol = 1e-4, max_count = 10000):\n",
    "    w = [w_init]    \n",
    "    it = 0\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    count = 0\n",
    "    check_w_after = 20\n",
    "    while count < max_count:\n",
    "        # mix data \n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = y[i]\n",
    "            zi = sigmoid(np.dot(w[-1].T, xi))\n",
    "            w_new = w[-1] + eta*(yi - zi)*xi\n",
    "            count += 1\n",
    "            # stopping criteria\n",
    "            if count%check_w_after == 0:                \n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol:\n",
    "                    return w\n",
    "            w.append(w_new)\n",
    "    return w\n",
    "\n",
    "np.random.seed(2)\n",
    "eta = .05 \n",
    "d = X.shape[0]\n",
    "w_init = np.random.randn(d, 1)\n",
    "w = logistic_sigmoid_regression(X, y, w_init, eta)\n",
    "np.save(\"LogisticRegression\", w[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7160000000000005\n",
      "Accuracy: 83.99004944565584 %\n"
     ]
    }
   ],
   "source": [
    "res1 = np.dot(w[-1].T, X)\n",
    "res1 = (res1-res1.mean())/res1.std()\n",
    "result = sigmoid(res1)[0]\n",
    "\n",
    "cnt = 0\n",
    "# print(result)\n",
    "threshold = [0]\n",
    "while len(threshold) <= 500:\n",
    "    threshold.append(threshold[-1] + 0.002)\n",
    "    \n",
    "\n",
    "maxAcc = -1\n",
    "maxThreshold = -1\n",
    "for j in threshold:\n",
    "    cnt = 0\n",
    "    for i in range(len(result)):\n",
    "        if result[i] < j:\n",
    "            cnt += (y[i] == 0)\n",
    "        else:\n",
    "            cnt += (y[i] == 1)\n",
    "    if cnt > maxAcc:\n",
    "        maxAcc = cnt\n",
    "        maxThreshold = j\n",
    "        \n",
    "cnt = 0\n",
    "print(maxThreshold)\n",
    "for i in range(len(result)):\n",
    "        if result[i] < maxThreshold:\n",
    "            cnt += (y[i] == 0)\n",
    "        else:\n",
    "            cnt += (y[i] == 1)\n",
    "            \n",
    "print(\"Accuracy:\", (cnt/len(result)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.82848064],\n",
       "       [ 1.78661481],\n",
       "       [ 3.38132172],\n",
       "       [ 2.36459297],\n",
       "       [ 0.68547538],\n",
       "       [-1.06064604],\n",
       "       [-1.03659969],\n",
       "       [-0.95548822],\n",
       "       [-1.32112009],\n",
       "       [-1.30389932],\n",
       "       [-1.51184101],\n",
       "       [-0.90108398],\n",
       "       [ 0.09013051],\n",
       "       [ 0.02496596],\n",
       "       [ 0.73889474],\n",
       "       [ 1.80408098],\n",
       "       [-0.65217306],\n",
       "       [ 0.91780443],\n",
       "       [-0.92628362],\n",
       "       [ 1.64873596],\n",
       "       [-0.26922246],\n",
       "       [ 0.24397896],\n",
       "       [ 2.4380664 ],\n",
       "       [-1.4412857 ],\n",
       "       [-0.23416763],\n",
       "       [ 0.07866051],\n",
       "       [-1.32391147],\n",
       "       [-2.03023065],\n",
       "       [-1.47363428],\n",
       "       [-0.95091834],\n",
       "       [-0.16641284],\n",
       "       [ 1.1655004 ],\n",
       "       [-2.05298348],\n",
       "       [-0.10105059],\n",
       "       [ 0.37350253],\n",
       "       [ 0.89170025],\n",
       "       [ 0.45310446],\n",
       "       [-0.72653837],\n",
       "       [ 0.17752326],\n",
       "       [ 0.58803157],\n",
       "       [ 0.1552537 ],\n",
       "       [ 0.53576036],\n",
       "       [-1.75997019],\n",
       "       [ 1.39886011],\n",
       "       [ 1.46312815],\n",
       "       [-0.35629895],\n",
       "       [ 0.39294138],\n",
       "       [ 0.0556582 ],\n",
       "       [-0.85494405],\n",
       "       [ 0.05214657],\n",
       "       [ 0.93374751],\n",
       "       [ 0.07468796],\n",
       "       [-0.34963312],\n",
       "       [-0.07331616],\n",
       "       [ 0.2707378 ],\n",
       "       [-0.19680352],\n",
       "       [-0.64119217],\n",
       "       [ 0.38854121],\n",
       "       [ 0.12170442],\n",
       "       [-0.68378349],\n",
       "       [-0.28684664],\n",
       "       [-0.14774989],\n",
       "       [-0.16788219],\n",
       "       [ 0.30548554],\n",
       "       [-1.87251202],\n",
       "       [-0.12204585],\n",
       "       [-0.68344968],\n",
       "       [-1.39020686],\n",
       "       [ 0.53672296],\n",
       "       [ 0.14693682],\n",
       "       [-0.49431531],\n",
       "       [ 0.23283679],\n",
       "       [-0.39312772],\n",
       "       [ 0.31275379],\n",
       "       [ 1.03563103],\n",
       "       [-0.85820574],\n",
       "       [-0.66964962],\n",
       "       [-0.22497344],\n",
       "       [-0.67689097],\n",
       "       [-2.03679391],\n",
       "       [ 0.77541251],\n",
       "       [ 0.74003905],\n",
       "       [ 0.44146021],\n",
       "       [ 0.9436125 ],\n",
       "       [ 0.33852656],\n",
       "       [-0.75312933],\n",
       "       [ 0.26949092],\n",
       "       [-0.23611171],\n",
       "       [-0.57587577],\n",
       "       [-0.02661137],\n",
       "       [ 0.14509719],\n",
       "       [-0.01070367],\n",
       "       [-0.5868807 ],\n",
       "       [-1.36857492],\n",
       "       [-0.3412439 ],\n",
       "       [ 1.61249355],\n",
       "       [-1.48549454],\n",
       "       [-0.76289155],\n",
       "       [ 0.6996876 ],\n",
       "       [-0.10054729],\n",
       "       [ 1.11932128],\n",
       "       [-0.02963354],\n",
       "       [ 0.3728949 ],\n",
       "       [-0.35929364],\n",
       "       [-0.37730215],\n",
       "       [ 2.2257356 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = np.load(\"LogisticRegression.npy\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = preprocessingData(testX)\n",
    "testX = testX.to_numpy()\n",
    "testY = dataReader.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = testX.T\n",
    "# testY = testY.T\n",
    "testX = np.concatenate((np.ones((1, testX.shape[1])), testX), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.82848064],\n",
       "       [ 1.78661481],\n",
       "       [ 3.38132172],\n",
       "       [ 2.36459297],\n",
       "       [ 0.68547538],\n",
       "       [-1.06064604],\n",
       "       [-1.03659969],\n",
       "       [-0.95548822],\n",
       "       [-1.32112009],\n",
       "       [-1.30389932],\n",
       "       [-1.51184101],\n",
       "       [-0.90108398],\n",
       "       [ 0.09013051],\n",
       "       [ 0.02496596],\n",
       "       [ 0.73889474],\n",
       "       [ 1.80408098],\n",
       "       [-0.65217306],\n",
       "       [ 0.91780443],\n",
       "       [-0.92628362],\n",
       "       [ 1.64873596],\n",
       "       [-0.26922246],\n",
       "       [ 0.24397896],\n",
       "       [ 2.4380664 ],\n",
       "       [-1.4412857 ],\n",
       "       [-0.23416763],\n",
       "       [ 0.07866051],\n",
       "       [-1.32391147],\n",
       "       [-2.03023065],\n",
       "       [-1.47363428],\n",
       "       [-0.95091834],\n",
       "       [-0.16641284],\n",
       "       [ 1.1655004 ],\n",
       "       [-2.05298348],\n",
       "       [-0.10105059],\n",
       "       [ 0.37350253],\n",
       "       [ 0.89170025],\n",
       "       [ 0.45310446],\n",
       "       [-0.72653837],\n",
       "       [ 0.17752326],\n",
       "       [ 0.58803157],\n",
       "       [ 0.1552537 ],\n",
       "       [ 0.53576036],\n",
       "       [-1.75997019],\n",
       "       [ 1.39886011],\n",
       "       [ 1.46312815],\n",
       "       [-0.35629895],\n",
       "       [ 0.39294138],\n",
       "       [ 0.0556582 ],\n",
       "       [-0.85494405],\n",
       "       [ 0.05214657],\n",
       "       [ 0.93374751],\n",
       "       [ 0.07468796],\n",
       "       [-0.34963312],\n",
       "       [-0.07331616],\n",
       "       [ 0.2707378 ],\n",
       "       [-0.19680352],\n",
       "       [-0.64119217],\n",
       "       [ 0.38854121],\n",
       "       [ 0.12170442],\n",
       "       [-0.68378349],\n",
       "       [-0.28684664],\n",
       "       [-0.14774989],\n",
       "       [-0.16788219],\n",
       "       [ 0.30548554],\n",
       "       [-1.87251202],\n",
       "       [-0.12204585],\n",
       "       [-0.68344968],\n",
       "       [-1.39020686],\n",
       "       [ 0.53672296],\n",
       "       [ 0.14693682],\n",
       "       [-0.49431531],\n",
       "       [ 0.23283679],\n",
       "       [-0.39312772],\n",
       "       [ 0.31275379],\n",
       "       [ 1.03563103],\n",
       "       [-0.85820574],\n",
       "       [-0.66964962],\n",
       "       [-0.22497344],\n",
       "       [-0.67689097],\n",
       "       [-2.03679391],\n",
       "       [ 0.77541251],\n",
       "       [ 0.74003905],\n",
       "       [ 0.44146021],\n",
       "       [ 0.9436125 ],\n",
       "       [ 0.33852656],\n",
       "       [-0.75312933],\n",
       "       [ 0.26949092],\n",
       "       [-0.23611171],\n",
       "       [-0.57587577],\n",
       "       [-0.02661137],\n",
       "       [ 0.14509719],\n",
       "       [-0.01070367],\n",
       "       [-0.5868807 ],\n",
       "       [-1.36857492],\n",
       "       [-0.3412439 ],\n",
       "       [ 1.61249355],\n",
       "       [-1.48549454],\n",
       "       [-0.76289155],\n",
       "       [ 0.6996876 ],\n",
       "       [-0.10054729],\n",
       "       [ 1.11932128],\n",
       "       [-0.02963354],\n",
       "       [ 0.3728949 ],\n",
       "       [-0.35929364],\n",
       "       [-0.37730215],\n",
       "       [ 2.2257356 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.array(model)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res1 = np.dot(W.T, testX)\n",
    "res1 = (res1-res1.mean())/res1.std()\n",
    "result = sigmoid(res1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.09188624777347 %\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(result)):\n",
    "    if result[i] < maxThreshold:\n",
    "        cnt += (testY[i] == \"<=50K.\" or testY[i] == \"<=50K\")\n",
    "    else:\n",
    "        cnt += (testY[i] == \">50K\" or testY[i] == \">50K.\")\n",
    "print(\"Accuracy:\", (cnt/len(result)) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
